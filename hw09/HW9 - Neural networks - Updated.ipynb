{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2019: Homework 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student name: Keshav Kothari\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Student id: 3034344473"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** You have now seen how Neural networks work. You have also seen how to create and visualize neural networks using Tensorflow and Tensorboard. In this Question, you will be working on Neural networks. You will be using MNIST data (labelled images of digits) that we discussed in the class to create vanilla dense Neural network model using **tensorflow** (You can use 1.x and 2.x as well, **You can use Tensorflow with Keras**) with the following characteristics:\n",
    "- Input layer size of 784 (Since each image is 28 * 28)\n",
    "- Three hidden layers of 300, 200 , 100\n",
    "- Output layer of 10 (Since 0 - 9 digits)\n",
    "- Use stochastic gradient descent\n",
    "- Any other requirements can be your choice\n",
    "\n",
    "\n",
    "Note that you have to define own functions for calculating loss function, optimizer to feed into the neural network. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Plot your neural network graph (using tensorboard) and the plot of performance results (Training and Validation accuracies and loss) for every epoch**\n",
    "\n",
    "Note: You can access MNIST data from **keras.datasets** [Link](https://keras.io/datasets/#mnist-database-of-handwritten-digits) or any standard available MNIST datasource (http://yann.lecun.com/exdb/mnist/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/keshav/anaconda3/envs/data-x/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 11s 235us/sample - loss: 0.2817 - acc: 0.9143 - val_loss: 0.1311 - val_acc: 0.9632\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 11s 227us/sample - loss: 0.1076 - acc: 0.9680 - val_loss: 0.1105 - val_acc: 0.9671\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.0743 - acc: 0.9768 - val_loss: 0.0905 - val_acc: 0.9743\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 11s 233us/sample - loss: 0.0518 - acc: 0.9836 - val_loss: 0.0911 - val_acc: 0.9744\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 11s 227us/sample - loss: 0.0388 - acc: 0.9876 - val_loss: 0.0817 - val_acc: 0.9762\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.0706 - acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07064836732036202, 0.9772]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(300, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "loss = losses.sparse_categorical_crossentropy\n",
    "model1.compile(loss=loss,\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "history = model1.fit(x_train, y_train, validation_split=0.2, epochs=5, callbacks=[tbCallBack])\n",
    "model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Graph\n",
    "![alt text](graph_run=.png \"Network Graph\")\n",
    "Training Loss\n",
    "<img src=\"epoch_loss_1.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Training Accuracy\n",
    "<img src=\"epoch_acc_1.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Validation Loss\n",
    "<img src=\"epoch_val_loss_1.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Validation Accuracy\n",
    "<img src=\"epoch_val_acc_1.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Use transfer learning and use the Imagenet VGG16 model to train on MNIST data. You can use **Keras** for solving this question. You can choose any requirements on loss function, optimizer etc. **Plot the performance results (Training and Validation accuracies & loss) for every epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "img_dim_ordering = 'tf'\n",
    "K.set_image_dim_ordering(img_dim_ordering)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# the model\n",
    "def pretrained_model(img_shape, num_classes):\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "    # Make vgg16 model layers as non trainable\n",
    "    for layer in model_vgg16_conv.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #Create your own input format\n",
    "    keras_input = Input(shape=img_shape, name = 'image_input')\n",
    "    \n",
    "    #Use the generated model \n",
    "    output_vgg16_conv = model_vgg16_conv(keras_input)\n",
    "    \n",
    "    #Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(256, activation='relu', name='fc1')(x)\n",
    "    x = Dense(64, activation='relu', name='fc2')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #Create your own model \n",
    "    pretrained_model = Model(inputs=keras_input, outputs=x)\n",
    "    return pretrained_model\n",
    "\n",
    "# converting it to RGB\n",
    "x_train = [cv2.cvtColor(cv2.resize(i, (32,32)), cv2.COLOR_GRAY2BGR) for i in x_train]\n",
    "x_train = np.concatenate([arr[np.newaxis] for arr in x_train]).astype('float32')\n",
    "\n",
    "x_test = [cv2.cvtColor(cv2.resize(i, (32,32)), cv2.COLOR_GRAY2BGR) for i in x_test]\n",
    "x_test = np.concatenate([arr[np.newaxis] for arr in x_test]).astype('float32')\n",
    "\n",
    "# training the model\n",
    "model2= pretrained_model(x_train.shape[1:], len(set(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshav/anaconda3/envs/data-x/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 147s 3ms/step - loss: 0.4511 - acc: 0.8901 - val_loss: 0.2128 - val_acc: 0.9312\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 144s 3ms/step - loss: 0.1893 - acc: 0.9390 - val_loss: 0.2103 - val_acc: 0.9313\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model2.fit(x_train, y_train, nb_epoch=2, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20951285454928875, 0.9317]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_epoch = range(0,2)\n",
    "plt.plot(num_epoch,history.history['val_loss'],label='validation_loss')\n",
    "plt.plot(num_epoch,history.history['val_acc'],label='validation_accuracy')\n",
    "plt.plot(num_epoch,history.history['loss'],label='train_loss')\n",
    "plt.plot(num_epoch,history.history['acc'],label='train_accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Performance results (Training and Validation accuracies & loss) for every epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT Q.** **(MANDATORY for students taking IND ENG 290)** Customize your neural networks in **Q1** to how many ever layers you want, use [batch normalization](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) and [Adam Optimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) and try different regularization techniques to combat overfitting. Also use as many iterations you want and plot every 10th iteration on the tensorboard. We will give extra credit if you achieve more than **98.5%** on the MNIST data. **Plot the neural network graph (using tensorboard) and describe the settings that you used and the performance results. Also plot performance results (Training and Validation accuracies & loss) for every epoch**\n",
    "\n",
    "Note: You can use Keras if necessary for solving this question. In case you are using Keras and are unable to plot the neural network graph, plot only the performance results.\n",
    "\n",
    "If you cannot run your tensorflow notebooks locally, you can use. \n",
    "https://datahub.berkeley.edu/hub/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 28s 514us/sample - loss: 0.2534 - acc: 0.9228 - val_loss: 0.1044 - val_acc: 0.9695\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 25s 472us/sample - loss: 0.1435 - acc: 0.9561 - val_loss: 0.0825 - val_acc: 0.9767\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 26s 476us/sample - loss: 0.1136 - acc: 0.9642 - val_loss: 0.0772 - val_acc: 0.9783\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 25s 468us/sample - loss: 0.1014 - acc: 0.9676 - val_loss: 0.0679 - val_acc: 0.9802\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 25s 467us/sample - loss: 0.0828 - acc: 0.9730 - val_loss: 0.0726 - val_acc: 0.9817\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 25s 467us/sample - loss: 0.0759 - acc: 0.9753 - val_loss: 0.0685 - val_acc: 0.9815\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 25s 470us/sample - loss: 0.0666 - acc: 0.9792 - val_loss: 0.0640 - val_acc: 0.9840\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 26s 473us/sample - loss: 0.0647 - acc: 0.9790 - val_loss: 0.0646 - val_acc: 0.9835\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 25s 471us/sample - loss: 0.0555 - acc: 0.9823 - val_loss: 0.0632 - val_acc: 0.9837\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 25s 469us/sample - loss: 0.0543 - acc: 0.9816 - val_loss: 0.0678 - val_acc: 0.9825\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 25s 471us/sample - loss: 0.0497 - acc: 0.9841 - val_loss: 0.0713 - val_acc: 0.9830\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 25s 470us/sample - loss: 0.0460 - acc: 0.9850 - val_loss: 0.0793 - val_acc: 0.9800\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 25s 470us/sample - loss: 0.0421 - acc: 0.9857 - val_loss: 0.0763 - val_acc: 0.9818\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 25s 464us/sample - loss: 0.0437 - acc: 0.9853 - val_loss: 0.0606 - val_acc: 0.9853\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 25s 471us/sample - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0714 - val_acc: 0.9825\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 25s 468us/sample - loss: 0.0379 - acc: 0.9874 - val_loss: 0.0630 - val_acc: 0.9860\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 25s 469us/sample - loss: 0.0377 - acc: 0.9877 - val_loss: 0.0568 - val_acc: 0.9865\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 26s 474us/sample - loss: 0.0342 - acc: 0.9886 - val_loss: 0.0630 - val_acc: 0.9848\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 25s 468us/sample - loss: 0.0316 - acc: 0.9893 - val_loss: 0.0612 - val_acc: 0.9865\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 26s 473us/sample - loss: 0.0315 - acc: 0.9892 - val_loss: 0.0619 - val_acc: 0.9857\n",
      "10000/10000 [==============================] - 2s 168us/sample - loss: 0.0577 - acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05769822396981836, 0.985]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.optimizers import SGD,Adam,RMSprop,Adadelta\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "model3 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "opt = Adam()\n",
    "loss = losses.categorical_crossentropy\n",
    "model3.compile(loss=loss,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "tbCallBack = TensorBoard(log_dir='./Graph_3', histogram_freq=0, write_graph=True, write_images=True)\n",
    "history = model3.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks=[tbCallBack], shuffle=True)\n",
    "model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "tf.keras.models.save_model(model3,'./98_5_dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Graph\n",
    "![alt text](graph_3.png \"Network Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loss\n",
    "<img src=\"epoch_loss.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Training Accuracy\n",
    "<img src=\"epoch_acc.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Validation Loss\n",
    "<img src=\"epoch_val_loss.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Validation Accuracy\n",
    "<img src=\"epoch_val_acc.svg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Description\n",
    "\n",
    "I tried increasing the layer size and layer depth but they saturated at around 98% accuracy. I googled for what people used and most of them indicated using CNNs to get accuracy above 98% which we we're allowed to. The question indicated that overfitting might be the issue because of which I limited my layer size to 2, with dimensions of 512 and 256 which seemed to work best for the users. I further added batch normalization and dropouts (20%) to combat overfitting. The Adam optimizer was used as asked for in the question. I tried various loss functions and eventually categorical_crossentropy got me over the hurdle. I also had to adjust the validation percentage to 0.1 to have more training data to train on with 20 epoch. I tried using a lower batch size but that took too long to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 132us/sample - loss: 0.0577 - acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05769822396981836, 0.985]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model again\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "model4 = tf.keras.models.load_model('./98_5_dense')\n",
    "model4.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-x)",
   "language": "python",
   "name": "data-x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
